{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6de23665-ccc4-4c5f-8c85-a451593d8450",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PyCity Schools Analysis\n",
    "\n",
    "Because the available data comes from two separate CSV files, it is easier to create a larger dataframe that incorporates data from both data sets. We will first have to find the paths of both files to pull the data from before merging the data sets. The first dataframe we'll create and analyze is the District Summary. This dataframe depicts the total number of schools, students, and budget; averages out the scores of the students; and shows the percentage of passing students. The a second dataframe will be created to further analyze the data by school. This dataframe shows what type of school it is, the student count per school, every schools' budget, budget per student, score averages of the students, and percentages of passing students. From this, we were able to conclude which schools were amongst the top 5 performing schools, and which ones were amongst the lowest performing ranks. Further analysis by subject, math and reading respectively, showed how well each grade level by school performed.  We also categorized the performance of each school according to its spending, size, and type. Through these results, we can conclude that:\n",
    "\n",
    "1. There is a slight negative correlation between per student spending and student performance. From the 'Scores by School Spending' summary table, we can see that the average scores and passing rates of the students were comparably higher when per spending ranges were less than $585. Conversely as the spending ranges increase, the scores and passing rates lowers. These results may suggest that there could be other factors aside from school spending that could determine a student's academic achievements. Such factors could be dependent on the class environment, student support services, curriculum, and teacher. \n",
    "\n",
    "2. Charter schools, which tend to have smaller student bodies, outperform public school districts across all metrics. From the \"Highest Performing Schools\" summary table, all top five schools are charter schools whereas all bottom five schools in the \"Lowest Performing Schools\" summary table are public schools. The \"Scores by School Type\" summary table also shows that the passing rates and averages are higher for charter schools. Reasons for this could be:\n",
    "    * A smaller class size garners more individual attention for each student - students can better retain information if they're getting more feedback from their instructors.\n",
    "    * Increased class engagement - because there are less students in each class, there are more opportunities to participate relative to time as opposed to the students in larger class sizes in public schools.\n",
    "    * Increased teacher satisfaction - there could be less stress for teachers teaching smaller class sizes, which correlates to burnout and job satisfaction. They can also develop better connection with each students since there are less students to cater to.\n",
    "    * Flexibility - as opposed to school districts that adhere to state curriculum and management, charter schools have more flexibility to adapt to their students needs.\n",
    "\n",
    "    While all of these reasons could factor into the high performance of students at charter schools, not all charter schools are high performing just as there are public schools that outperform charter schools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b1c33-3389-46e1-8d7d-bce64491beb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Find Path\n",
    "school_data_path = Path(\"Resources/schools_complete.csv\")\n",
    "student_data_path = Path(\"Resources/students_complete.csv\")\n",
    "\n",
    "# Read files and import into Dataframes\n",
    "school_data = pd.read_csv(school_data_path)\n",
    "student_data = pd.read_csv(student_data_path)\n",
    "\n",
    "# Merge the two datasets into one\n",
    "merged_data = pd.merge(student_data, school_data, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d08b675-9696-4cfb-accc-1f99fcf94d74",
   "metadata": {
    "tags": []
   },
   "source": [
    "# District Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3b37c-3db0-4e4b-ac6d-4ed7d4dee2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of unique schools\n",
    "total_schools = len(merged_data['school_name'].unique())\n",
    "print (total_schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44faac74-6e3d-4504-aac1-e9553a3b7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total students\n",
    "total_students = len(merged_data['Student ID'].unique())\n",
    "print (total_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fbe5ca-a5bc-4d64-bc38-d6d8b4c68d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total budget\n",
    "total_budget = school_data.budget.sum()\n",
    "print (total_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a5b2b6-c184-49ad-a64f-23c625479db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average math score\n",
    "avg_math = merged_data.math_score.mean()\n",
    "print (avg_math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60040f1d-8548-4bd3-9818-750c36e4a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average reading score\n",
    "avg_reading = merged_data.reading_score.mean()\n",
    "print (avg_reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc324940-e2fb-45a5-a723-ae3be33c1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % passing math (the percentage of students who passed math)\n",
    "passing_mcount = merged_data[merged_data[\"math_score\"] >=70].count()[\"student_name\"]\n",
    "print(passing_mcount)\n",
    "passing_mpercentage = passing_mcount/total_students * 100\n",
    "print(passing_mpercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851efe91-05c2-4749-b6e7-9bdc8ac5f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % passing reading (the percentage of students who passed reading)\n",
    "passing_rcount = merged_data[merged_data[\"reading_score\"] >=70].count()[\"student_name\"]\n",
    "print(passing_rcount)\n",
    "passing_rpercentage = passing_rcount/total_students * 100\n",
    "print(passing_rpercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e025bd-7f9a-432b-a3ca-0d9ddf200035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % overall passing (the percentage of students who passed math AND reading)\n",
    "pass_count = merged_data[(merged_data[\"reading_score\"] >=70) & (merged_data[\"math_score\"] >=70)].count()[\"student_name\"]\n",
    "print(pass_count)\n",
    "pass_percentage = pass_count/total_students * 100\n",
    "print(pass_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61111690-8b5b-4318-b76a-bffb06288765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a high-level snapshot of the district's key metrics in a Dataframe\n",
    "district_summary = pd.DataFrame({\n",
    "    \"Total Schools\": f\"{total_schools}\",\n",
    "    \"Total Students\": f\"{total_students:,}\",\n",
    "    \"Total Budget\": f\"${total_budget:,}\",\n",
    "    \"Average Math Score\": f\"{avg_math:.5f}\",\n",
    "    \"Average Reading Score\": f\"{avg_reading:.5f}\", \n",
    "    \"% Passing Math\": f\"{passing_mpercentage:.5f}%\",\n",
    "    \"% Passing Reading\": f\"{passing_rpercentage:.5f}%\", \n",
    "    \"% Overall Passing\": f\"{pass_percentage:.5f}%\"\n",
    "                                               }, index=[0])\n",
    "\n",
    "district_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a9ed24-6603-4940-973a-0fddcd422b75",
   "metadata": {
    "tags": []
   },
   "source": [
    "# School Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9fcda3-baa9-4481-899d-b2402d810baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a variable to store merged dataframe \n",
    "df = pd.DataFrame(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15604e64-02b3-4ed1-a7eb-30ff1f7f271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# School types\n",
    "school_types = merged_data.groupby(\"school_name\")[\"type\"].first()\n",
    "school_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71718725-27c0-4af6-a96d-f1ab2d34f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total students per school\n",
    "school_students = df.groupby(\"school_name\")[\"student_name\"].count()\n",
    "school_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ec6a8-fb03-4d06-88d3-d943dcf204b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total school budget\n",
    "school_budget = df.groupby([\"school_name\"])[\"budget\"].mean()\n",
    "school_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31099883-8f1f-49a4-b086-7dd9acfc8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per student budget\n",
    "per_student_budget = school_budget/school_students\n",
    "per_student_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dfacea-fc21-4bbe-8e6e-b3e5d86d7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average math score\n",
    "avg_math_per_school =df.groupby([\"school_name\"])[\"math_score\"].mean()\n",
    "avg_math_per_school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a3e5a-f590-44b8-b108-c07a60e6c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average reading score\n",
    "avg_reading_per_school = df.groupby([\"school_name\"])[\"reading_score\"].mean()\n",
    "avg_reading_per_school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63422d-6ade-43c4-a694-65f22adb449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % passing math (the percentage of students who passed math)\n",
    "passing_math_students = df[df[\"math_score\"] >=70].groupby(\"school_name\")[\"student_name\"].count()\n",
    "passing_math_percentage = passing_math_students/ school_students * 100\n",
    "\n",
    "passing_math_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812d2ae-c90a-4137-becd-a5114080ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % passing reading (the percentage of students who passed reading)\n",
    "passing_reading_students = df[df[\"reading_score\"] >=70].groupby(\"school_name\")[\"student_name\"].count()\n",
    "passing_reading_percentage = passing_reading_students/ school_students * 100\n",
    "\n",
    "passing_reading_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95133ff6-be5a-4b8a-833d-b498397be378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % overall passing (the percentage of students who passed math AND reading)\n",
    "overall_passing = df[(df[\"math_score\"] >=70) & (df[\"reading_score\"] >=70)].groupby(\"school_name\")[\"student_name\"].count()\n",
    "overall_passing_percentage = overall_passing/ school_students * 100\n",
    "\n",
    "overall_passing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d860920-5b26-4b82-9276-401502cccfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a high-level snapshot of each schools' key metrics in a Dataframe\n",
    "per_school_summary = pd.DataFrame({\n",
    "    \"School Type\": school_types, \n",
    "    \"Total Students\": school_students,\n",
    "    \"Total School Budget\": school_budget,\n",
    "    \"Per Student Budget\": per_student_budget,\n",
    "    \"Average Math Score\": avg_math_per_school,\n",
    "    \"Average Reading Score\": avg_reading_per_school,\n",
    "    \"% Passing Math\": passing_math_percentage,\n",
    "    \"% Passing Reading\": passing_reading_percentage,\n",
    "    \"% Overall Passing\": overall_passing_percentage\n",
    "        })\n",
    "\n",
    "#formatting\n",
    "per_school_summary[\"Total School Budget\"] = per_school_summary[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
    "per_school_summary[\"Per Student Budget\"] = per_school_summary[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
    "\n",
    "per_school_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9171ae23-63cd-4d64-8e85-9a38f4a5e959",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Highest-Performing Schools (by % Overall Passing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914966d9-76d7-4c78-a0b4-b5cb7e0628d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the schools by % Overall Passing in descending order and display the top 5 rows\n",
    "top_schools= per_school_summary.sort_values(by=\"% Overall Passing\", ascending = False)\n",
    "top_schools.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd5293-1380-4501-b7c7-4758f68d61be",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lowest-Performing Schools (by % Overall Passing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa183e-e057-46c8-8a18-1d0e49dcd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the schools by `% Overall Passing` in ascending order and display the top 5 rows.\n",
    "bottom_schools = per_school_summary.sort_values(by=\"% Overall Passing\", ascending = True)\n",
    "bottom_schools.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae4591-217f-48a0-a05f-baab76500cca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Math Scores by Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf571ae-08e4-45c0-b4f5-90c4f9a84856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary calculations to create a DataFrame that lists the average math score for students of each grade level\n",
    "\n",
    "# Separate by grade\n",
    "ninth_graders = df[(df[\"grade\"] == \"9th\")]\n",
    "tenth_graders = df[(df[\"grade\"] == \"10th\")]\n",
    "eleventh_graders = df[(df[\"grade\"] == \"11th\")]\n",
    "twelfth_graders = df[(df[\"grade\"] == \"12th\")]\n",
    "\n",
    "# Group by \"school_name\" and take the mean of each.\n",
    "ninth_graders_scores = ninth_graders.groupby(\"school_name\") [\"math_score\"].mean()\n",
    "tenth_graders_scores = tenth_graders.groupby(\"school_name\") [\"math_score\"].mean()\n",
    "eleventh_graders_scores = eleventh_graders.groupby(\"school_name\") [\"math_score\"].mean()\n",
    "twelfth_graders_scores = twelfth_graders.groupby(\"school_name\") [\"math_score\"].mean()\n",
    "\n",
    "# Combine each of the scores above into single DataFrame called `math_scores_by_grade`\n",
    "math_scores_by_grade = pd.DataFrame({\n",
    "    \"9th\": ninth_graders_scores,\n",
    "    \"10th\": tenth_graders_scores,\n",
    "    \"11th\": eleventh_graders_scores,\n",
    "    \"12th\": twelfth_graders_scores\n",
    "})\n",
    "\n",
    "# Minor data wrangling\n",
    "math_scores_by_grade.index.name = None\n",
    "\n",
    "# Display the DataFrame\n",
    "math_scores_by_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8a4fa9-a1bd-438e-af1f-9062bafbc975",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reading Score by Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe94927-1572-4bab-8580-1b6686d8b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary calculations to create a DataFrame that lists the average reading score for students of each grade level\n",
    "\n",
    "# Separate by grade\n",
    "ninth_graders = df[(df[\"grade\"] == \"9th\")]\n",
    "tenth_graders = df[(df[\"grade\"] == \"10th\")]\n",
    "eleventh_graders = df[(df[\"grade\"] == \"11th\")]\n",
    "twelfth_graders = df[(df[\"grade\"] == \"12th\")]\n",
    "\n",
    "# Group by \"school_name\" and take the mean of each.\n",
    "ninth_graders_scores = ninth_graders.groupby(\"school_name\") [\"reading_score\"].mean()\n",
    "tenth_graders_scores = tenth_graders.groupby(\"school_name\") [\"reading_score\"].mean()\n",
    "eleventh_graders_scores = eleventh_graders.groupby(\"school_name\") [\"reading_score\"].mean()\n",
    "twelfth_graders_scores = twelfth_graders.groupby(\"school_name\") [\"reading_score\"].mean()\n",
    "\n",
    "# Combine each of the scores above into single DataFrame called `math_scores_by_grade`\n",
    "reading_scores_by_grade = pd.DataFrame({\n",
    "    \"9th\": ninth_graders_scores,\n",
    "    \"10th\": tenth_graders_scores,\n",
    "    \"11th\": eleventh_graders_scores,\n",
    "    \"12th\": twelfth_graders_scores\n",
    "})\n",
    "\n",
    "# Minor data wrangling\n",
    "reading_scores_by_grade = reading_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
    "reading_scores_by_grade.index.name = None\n",
    "\n",
    "# Display the DataFrame\n",
    "reading_scores_by_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47bfb17-f816-4b64-8039-3a4895311608",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scores by School Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f104ec-446b-4b97-877b-d6f6eecad059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the bins \n",
    "spending_bins = [0, 585, 630, 645, 680]\n",
    "labels = [\"<$585\", \"$585-630\", \"$630-645\", \"$645-680\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad6540-f046-46a7-ab56-b1b7de51a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the school summary since it has the \"Per Student Budget\" \n",
    "school_spending_df = per_school_summary.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea3a99-fc1a-4a26-8904-b447415c1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `pd.cut` to categorize spending based on the bins.\n",
    "school_spending_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_student_budget, spending_bins, labels=labels) \n",
    "school_spending_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5e0c2-8a30-4a3e-b24e-6a353bee20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Calculate averages for the desired columns. \n",
    "spending_math_scores = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"Average Math Score\"].mean()\n",
    "spending_reading_scores = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"Average Reading Score\"].mean()\n",
    "spending_passing_math = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"% Passing Math\"].mean()\n",
    "spending_passing_reading = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"% Passing Reading\"].mean()\n",
    "overall_passing_spending = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"% Overall Passing\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff566f4c-2a1d-4fcd-b294-a39412dd0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble into DataFrame\n",
    "spending_summary = pd.DataFrame ({\n",
    "    \"Average Math Score\": spending_math_scores,\n",
    "    \"Average Reading Score\": spending_reading_scores,\n",
    "    \"% Passing Math\": spending_passing_math,\n",
    "    \"% Passing Reading\": spending_passing_reading,\n",
    "    \"% Overall Passing\": overall_passing_spending\n",
    "})\n",
    "\n",
    "# Display results\n",
    "spending_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c3f10-f54a-44c2-92ac-b5e6f79320ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scores by School Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e6ce3d-8023-478d-b759-1b97e61793de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the bins.\n",
    "size_bins = [0, 1000, 2000, 5000]\n",
    "labels = [\"Small (<1000)\", \"Medium (1000-2000)\", \"Large (2000-5000)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6ea62-18f2-4af6-89ac-b953efc92c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize the spending based on the bins\n",
    "# Use `pd.cut` on the \"Total Students\" column of the `per_school_summary` DataFrame.\n",
    "\n",
    "per_school_summary[\"School Size\"] = pd.cut(school_students, bins = size_bins, labels = labels)\n",
    "per_school_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0428477-ae14-4f90-9b57-9f649868b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages for the desired columns. \n",
    "size_math_scores = per_school_summary.groupby([\"School Size\"])[\"Average Math Score\"].mean()\n",
    "size_reading_scores = per_school_summary.groupby([\"School Size\"])[\"Average Reading Score\"].mean()\n",
    "size_passing_math = per_school_summary.groupby([\"School Size\"])[\"% Passing Math\"].mean()\n",
    "size_passing_reading = per_school_summary.groupby([\"School Size\"])[\"% Passing Reading\"].mean()\n",
    "size_overall_passing = per_school_summary.groupby([\"School Size\"])[\"% Overall Passing\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6468686a-ef81-4ed7-b8e1-a34c80c823ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame called `size_summary` that breaks down school performance based on school size (small, medium, or large).\n",
    "# Use the scores above to create a new DataFrame called `size_summary`\n",
    "size_summary = pd.DataFrame({\n",
    "    \"Average Math Score\": size_math_scores,\n",
    "    \"Average Reading Score\": size_reading_scores,\n",
    "    \"% Passing Math\": size_passing_math,\n",
    "    \"% Passing Reading\": size_passing_reading,\n",
    "    \"% Overall Passing\": size_overall_passing\n",
    "})\n",
    "\n",
    "# Display results\n",
    "size_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64cd213-a42d-411c-a286-d9f7368f9e3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scores by School Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eda2b9-452b-48aa-b9d8-29504b771267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the per_school_summary DataFrame by \"School Type\" and average the results.\n",
    "type_math_scores = per_school_summary.groupby([\"School Type\"])[\"Average Math Score\"].mean()\n",
    "type_reading_scores = per_school_summary.groupby([\"School Type\"])[\"Average Reading Score\"].mean()\n",
    "type_passing_math = per_school_summary.groupby([\"School Type\"])[\"% Passing Math\"].mean()\n",
    "type_passing_reading = per_school_summary.groupby([\"School Type\"])[\"% Passing Reading\"].mean()\n",
    "type_overall_passing = per_school_summary.groupby([\"School Type\"])[\"% Overall Passing\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ce607-a79c-4b80-a58a-b341c610c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the new data by type into a DataFrame called `type_summary`\n",
    "type_summary = pd.DataFrame ({\n",
    "    \"Average Math Score\":type_math_scores ,\n",
    "    \"Average Reading Score\":type_reading_scores ,\n",
    "    \"% Passing Math\":type_passing_math ,\n",
    "    \"% Passing Reading\":type_passing_reading ,\n",
    "    \"% Overall Passing\":type_overall_passing \n",
    "})\n",
    "\n",
    "# Display results\n",
    "type_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
